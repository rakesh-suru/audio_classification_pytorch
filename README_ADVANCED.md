# ğŸ“˜ Quran Recitation Audio Classification using CNN & Mel-Spectrograms

![Deep Learning](https://img.shields.io/badge/Deep%20Learning-PyTorch-EE4C2C?style=for-the-badge)
![Python](https://img.shields.io/badge/Python-3.10-blue?style=for-the-badge)
![Status](https://img.shields.io/badge/Project-Active-brightgreen?style=for-the-badge)
![Dataset](https://img.shields.io/badge/Dataset-Kaggle-blue?style=for-the-badge)

A complete deep-learning pipeline for **Quran Recitation Classification** using **Mel-Spectrograms** and a **Convolutional Neural Network (CNN)** built with PyTorch.

This project includes:
- Dataset downloading  
- Audio preprocessing  
- Spectrogram generation  
- Model architecture  
- Training + Validation loops  
- Testing & Graph Visualization  

---

# ğŸ“‚ Dataset

**Source:** Kaggle â€“ *Quran Recitations for Audio Classification*  
The dataset consists of labeled Quran recitation audio files.

### **Processing Steps**
- Load audio using **Librosa**
- Convert to **Mel-Spectrogram (128 Ã— 256)**
- Normalize & resize
- Encode labels (`LabelEncoder`)
- Split into:
  - **70% Train**
  - **15% Validation**
  - **15% Test**

---

# ğŸ§  Model Architecture

### **Custom CNN**
```
Conv2D â†’ ReLU â†’ MaxPool2D â†’ Dropout
Conv2D â†’ ReLU â†’ MaxPool2D â†’ Dropout
Conv2D â†’ ReLU â†’ MaxPool2D â†’ Dropout
Flatten â†’ Fully Connected Layers â†’ Output
```

### Hyperparameters
| Parameter | Value |
|----------|--------|
| Optimizer | Adam |
| Loss | CrossEntropyLoss |
| Epochs | 25 |
| LR | 1e-4 |
| Batch Size | 16 |

---

# ğŸ› ï¸ Project Workflow

## 1ï¸âƒ£ Data Preparation
- Load CSV  
- Fix file paths  
- Encode labels  
- Generate Mel-Spectrogram  
- Resize to consistent dimensions  

## 2ï¸âƒ£ Dataset Loader
- Custom PyTorch Dataset  
- Preloads spectrogram tensors  
- Returns `(audio_tensor, label)`  

## 3ï¸âƒ£ Training Loop
Tracks:
- Loss (Train + Validation)
- Accuracy (Train + Validation)
- GPU acceleration if available

## 4ï¸âƒ£ Evaluation
- Test accuracy  
- Loss & Accuracy plots  

---

# ğŸ“ˆ Visualizations

The notebook generates:

### **Training vs Validation Loss**
### **Training vs Validation Accuracy**

Both graphs help detect overfitting and overall model performance.

---

# ğŸ“ Recommended Project Structure

```
ğŸ“¦ Quran-Audio-Classification
â”œâ”€â”€ README.md
â”œâ”€â”€ audio_classification.ipynb
â”œâ”€â”€ Dataset/
â”‚   â”œâ”€â”€ files_paths.csv
â”‚   â”œâ”€â”€ audio_files...
â”œâ”€â”€ models/
â”‚   â””â”€â”€ model.pth  (optional)
â””â”€â”€ plots/
    â”œâ”€â”€ accuracy.png
    â””â”€â”€ loss.png
```

---

# â–¶ï¸ How to Run

### Install dependencies
```
pip install opendatasets librosa torch scikit-learn matplotlib numpy scikit-image torchsummary
```

### Download dataset
```
import opendatasets as od
od.download("https://www.kaggle.com/datasets/mohammedalrajeh/quran-recitations-for-audio-classification")
```

### Run notebook
Use **GPU (Colab recommended)** for faster training.

---

# ğŸš€ Future Improvements

- âœ” Add **SpecAugment**
- âœ” Use **CRNN (CNN + GRU/LSTM)**
- âœ” Replace CNN with **ResNet18 / MobileNetV2**
- âœ” Add **training-progress callbacks**
- âœ” Deploy as **Streamlit App**
- âœ” Export as **ONNX / TorchScript**

---

# ğŸ¤ Contributions

Pull requests are welcome!  
Feel free to:
- Improve model accuracy  
- Optimize preprocessing  
- Add new architectures  
- Enhance documentation  

---

# âœ¨ Author

**Rakesh Suru**  
Deep Learning â€¢ Audio Processing â€¢ PyTorch  
